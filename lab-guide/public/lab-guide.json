[{"id":"1","name":"Prerequisites","content":"<h2 id=\"prerequisites\">Prerequisites</h2>\n<p>During this hands-on training, we will use the Dynatrace playground with Notebooks and Dashboards to explore the following:</p>\n<ol>\n<li><strong>Data Transformation</strong>: Learn how to effectively use the <code>join</code>, <code>lookup</code>, <code>append</code>, and <code>data</code> commands to combine data from multiple sources, enhancing the depth and breadth of your queries.</li>\n<li><strong>Data Optimization</strong>: Optimize your DQL queries with sampling, entity usage, and timeseries data, enabling better performance monitoring and analysis.</li>\n<li><strong>Aggregate Complex Queries</strong>: Explore techniques for aggregating complex queries using workflows and business events, allowing for more comprehensive data analysis and reporting.</li>\n</ol>\n<p>By the end of this session, students will have a deeper understanding of advanced DQL features, empowering them to leverage Dynatrace for more sophisticated and efficient data analysis.</p>\n<h3 id=\"trainingprerequisites\">Training Prerequisites</h3>\n<ul>\n<li>Dynatrace Playground access and/or personal sandbox tenant access</li>\n</ul>\n<h3 id=\"optional\">Optional</h3>\n<ul>\n<li>Access to <code>tacocorp</code> - SE sandbox: <a href=\"https://bwm98081.apps.dynatrace.com/\">tacocorp</a></li>\n</ul>","activityList":[{"id":"1.1","name":"Dynatrace Playground Access","content":"<h2 id=\"dynatraceplaygroundaccess\">Dynatrace Playground Access</h2>\n<p>Ensure you can reach the Dynatrace playground: <a href=\"https://wkf10640.apps.dynatrace.com/\">Playground</a>.</p>\n<p><img src=\"assets/playground.png\" alt=\"Playground\" /></p>\n<p>For workflows, we will use <strong>tacocorp</strong>, an SE sandbox from Kyle Harrington and team, to test DQL aggregations and post the results as business events. Please ensure you can access it: <a href=\"https://bwm98081.apps.dynatrace.com/\">tacocorp</a>. If you cannot, please put your email in the chat, and an instructor will invite you.</p>\n<p><img src=\"assets/tacocorp.png\" alt=\"tacocorp\" /></p>","activityList":[]}]},{"id":"2","name":"Data Transformation","content":"<h2 id=\"datatransformation\">Data Transformation</h2>\n<p>In this lab, we will explore how to transform data from various sources using <code>join</code>, <code>lookup</code>, <code>append</code>, and <code>data</code> commands. We will look at data from logs, traces, the entity model, and raw sources to accomplish this.</p>\n<p>Lab tasks:</p>\n<ol>\n<li>Adding Data with <code>data</code> and <code>append</code></li>\n<li>Connecting Data with <code>join</code> and <code>lookup</code></li>\n<li>Wrap Up</li>\n</ol>","activityList":[{"id":"2.1","name":"Adding Data with `data` and `append` ","content":"<h2 id=\"addingdatawithdataandappend\">Adding Data with <code>data</code> and <code>append</code></h2>\n<h3 id=\"importnotebookintodynatrace\">Import Notebook into Dynatrace</h3>\n<p><a href=\"https://github.com/popecruzdt/dt-k8s-otel-o11y-logs/blob/code-spaces/dt-k8s-otel-o11y-logs_dt_notebook.json\">Notebook</a></p>\n<h3 id=\"includingrawdatawithdata\">Including Raw Data with <code>data</code></h3>\n<p>The <code>data</code> command provides an easy way to add any data you care about into a Notebook, Dashboard, Workflow, or any other component that uses DQL. This is most useful when pulling in data from other sources (i.e., Excel, CSV, etc.) or consolidating data from another query into a DQL statement. </p>\n<p>Syntax:</p>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">data</span> record(key=value<span class=\"hljs-number\">1</span>),\n<span class=\"hljs-attribute\">record</span>(key=value<span class=\"hljs-number\">2</span>,key<span class=\"hljs-number\">2</span>=value<span class=\"hljs-number\">3</span>), ...\n</code></pre>\n<p>For example, let's say your customer has a product name on all their key applications, placed as tag metadata on those entities in Dynatrace. This value, <code>DT_RELEASE_PRODUCT</code>, does not change often; the customer only adds new apps every 6 months. Therefore, if we use a query to return those <code>DT_RELEASE_PRODUCT</code> values, we can then build them as a new <code>data</code> array for subsequent queries without having to have to run a DQL <code>fetch</code>.</p>\n<p>Extract the tags as a string for all of the process group instances (PGIs) in the environment, and parse out the <code>DT_RELEASE_PRODUCT</code> values.</p>\n<pre><code class=\"hljs\">fetch dt.entity.process<span class=\"hljs-number\">_</span>group<span class=\"hljs-number\">_</span>instance\n| fieldsAdd tags\n| fieldsAdd tagsToString = toString(tags)\n| parse tagsToString, <span class=\"hljs-string\">&quot;&quot;&quot;DATA &#x27;DT_RELEASE_PRODUCT:&#x27; LD:productName &#x27;\\&quot;,&#x27; DATA EOF&quot;&quot;&quot;</span>\n| filter isNotNull(productName)\n| summarize count=count(), <span class=\"hljs-meta\">by</span>:{productName}\n</code></pre>\n<p><strong>⏩ Try it out</strong>: Now, see if you can take the column <code>productName</code> and transform it into a new <code>data</code> array with the key <code>productName</code> and the value of these product names. Hint: you will need to use <code>concat</code> and export the data as a CSV. </p>\n<pre><code class=\"hljs\">fetch dt.entity.process_group_instance\n<span class=\"hljs-string\">| fieldsAdd tags</span>\n<span class=\"hljs-string\">| fieldsAdd tagsToString = toString(tags)</span>\n<span class=\"hljs-string\">| parse tagsToString, &quot;&quot;&quot;</span>DATA &#x27;DT_RELEASE_PRODUCT:&#x27; LD:productName &#x27;\\&quot;,&#x27; DATA EOF<span class=\"hljs-string\">&quot;&quot;&quot;</span>\n<span class=\"hljs-string\">| filter isNotNull(productName)</span>\n<span class=\"hljs-string\">| summarize count=count(), by:{productName}</span>\n<span class=\"hljs-string\">| fieldsAdd outputRecord = concat(&quot;</span>record(productName=\\<span class=\"hljs-string\">&quot;...&quot;</span>))\n</code></pre>\n<p><img src=\"assets/data_for_export.png\" alt=\"Data for Export\" /></p>\n<p>The ability to add data on demand - particularly for non-DQL data sources and for quasi-static, long-running DQL queries - is a powerful way to add data into your DQL statements.</p>\n<h3 id=\"rawjsondatatypeswithdata\">Raw JSON Data Types with <code>data</code></h3>\n<p>The <code>data</code> <a href=\"https://docs.dynatrace.com/docs/discover-dynatrace/references/dynatrace-query-language/commands/data-source-commands#data\">command</a> allows you to also pull in raw JSON content. </p>\n<p>The following is an example for nested JSON:</p>\n<pre><code class=\"hljs\">data <span class=\"hljs-type\">json</span>:&quot;&quot;&quot;[\n  {\n    &quot;dataRecord&quot;: {\n      &quot;<span class=\"hljs-type\">name</span>&quot;: &quot;jwoo1&quot;,\n      &quot;depositAmount&quot;: 112,\n      &quot;bankAccountId&quot;: 1234,\n      &quot;properties&quot;:\n      {\n        &quot;<span class=\"hljs-keyword\">type</span>&quot;: &quot;savings&quot;,\n        &quot;interestRate&quot;: 0.0045,\n        &quot;relatedAccounts&quot;:\n        {\n          &quot;savings&quot;: &quot;N/A&quot;,\n          &quot;checking&quot;: &quot;<span class=\"hljs-number\">2341</span>&quot;,\n          &quot;mmf&quot;: &quot;<span class=\"hljs-number\">1493</span>&quot;\n        }\n      }\n    }\n  },\n  {\n    &quot;dataRecord&quot;: {\n      &quot;<span class=\"hljs-type\">name</span>&quot;: &quot;jdoe2&quot;,\n      &quot;depositAmount&quot;: 343,\n      &quot;bankAccountId&quot;: 1120,\n      &quot;properties&quot;:\n      {\n        &quot;<span class=\"hljs-keyword\">type</span>&quot;: &quot;checking&quot;,\n        &quot;interestRate&quot;: 0.00325,\n        &quot;relatedAccounts&quot;:\n        {\n          &quot;savings&quot;: &quot;<span class=\"hljs-number\">3001</span>&quot;,\n          &quot;checking&quot;: &quot;N/A&quot;,\n          &quot;mmf&quot;: &quot;<span class=\"hljs-number\">8843</span>&quot;\n        }\n      }\n    }\n  },\n  {\n    &quot;dataRecord&quot;: {\n      &quot;<span class=\"hljs-type\">name</span>&quot;: &quot;jdoe3&quot;,\n      &quot;depositAmount&quot;: 8433,\n      &quot;bankAccountId&quot;: 1555\n    }\n  },\n  {\n    &quot;dataRecord&quot;: {\n      &quot;<span class=\"hljs-type\">name</span>&quot;: &quot;batman4&quot;,\n      &quot;depositAmount&quot;: 8433413,\n      &quot;bankAccountId&quot;: 1000,\n      &quot;properties&quot;:\n      {\n        &quot;<span class=\"hljs-keyword\">type</span>&quot;: &quot;savings&quot;,\n        &quot;interestRate&quot;: 0.0055,\n        &quot;relatedAccounts&quot;:\n        {\n          &quot;savings&quot;: &quot;N/A&quot;,\n          &quot;checking&quot;: &quot;<span class=\"hljs-number\">3499</span>&quot;,\n          &quot;mmf&quot;: &quot;<span class=\"hljs-number\">2224</span>&quot;\n        }\n      }\n    }\n  }\n]&quot;&quot;&quot;\n</code></pre>\n<p><strong>⏩ Try it out</strong>: For that example, copy the <code>data</code> record into your Notebook and determine the median deposit amount (<code>depositAmount</code>) from the data. </p>\n<p>Nested JSON like the example in the <code>data</code> record can be more easily parsed if flatted accordingly. This can be accomplished by using <code>fieldsFlatten</code>: <a href=\"https://docs.dynatrace.com/docs/discover-dynatrace/references/dynatrace-query-language/commands/structuring-commands#fieldsFlatten\">Documentation</a>. For JSON fields, you can provide a <code>depth</code> argument that then automatically extracts nested JSON fields and places those keys as their own variables in the record.</p>\n<p>For nested, lengthy JSON records, the <code>fieldsKeep</code> command proves useful: <a href=\"https://docs.dynatrace.com/docs/discover-dynatrace/references/dynatrace-query-language/commands/selection-and-modification-commands#fieldsKeep\">Documentation</a>. The <code>fieldsKeep</code> command retains only the records that match either an exact key or a key with wildcards. An example wildcard pattern for the above would be: <code>fieldsKeep \"dataRecord.name*\"</code></p>\n<p>In the case of that <code>fieldsKeep</code> pattern, only the <code>name</code> nested JSON keys and their respective values would be kept. Wildcards can be applied either as prefixes or suffixes (i.e., before and after the matching pattern).</p>\n<p><strong>⏩ Try it out</strong>: Using <code>fieldsFlatten</code>, <code>depth</code>, and <code>fieldsKeep</code>, count how many <code>relatedAccounts.savings</code> keys are defined.</p>\n<h3 id=\"addingdatasetswithappend\">Adding Data Sets With <code>append</code></h3>\n<p>The <code>append</code> command (<a href=\")\">Documentation</a> is one of three ways to add data to an existing DQL data set. This command behaves similarly to a <strong>SQL UNION ALL</strong> operation between two data sets <code>A</code> (i.e., \"left\") and <code>B</code> (i.e., \"right\"). A diagram showing that is below, highlighting the fact that the two sets have no excluded intersection and that the two sets may have duplicate values. However, the keys will still remain unique.</p>\n<p><img src=\"assets/append_set_diagram.png\" alt=\"append Set Logic\" /></p>\n<p>Example syntax for a DQL <code>fetch</code>:</p>\n<pre><code class=\"hljs\">fetch logs\n| fieldsAdd <span class=\"hljs-attribute\">keyValue</span>=<span class=\"hljs-string\">&quot;test&quot;</span>\n| limit 10\n| append\n[\n   data record(<span class=\"hljs-attribute\">keyValue</span>=<span class=\"hljs-string\">&quot;test2&quot;</span>, <span class=\"hljs-attribute\">content</span>=<span class=\"hljs-string\">&quot;Hello World&quot;</span>)\n]\n</code></pre>\n<p>In that example case, log records will have an additional key added to the records, <code>keyValue</code>, and its value will be fixed as <code>test</code>. With the <code>append</code> command, the <code>keyValue</code> key will have the value <code>test2</code> added as a record. Further, the <code>content</code> key from the previous log DQL statement will have the value <code>Hello World</code>. Therefore, the total record count from the query will be 11, 10 from the logs and 1 from the <code>append</code>, with the keys <code>keyValue</code> and <code>content</code> having non-null entries on all records. </p>\n<p>A potentially useful scenario for <code>append</code> is when you have multiple metric queries that you want to \"glue\" together, regardless of whether you have a common value between <code>A</code> (\"left\") and <code>B</code> (\"right\"). For instance, if you wanted to show the timeseries for host idle CPU over the last 2 hours and in the same window 7 days ago, you could accomplish that with <code>append</code>, as seen below. </p>\n<p>Another useful scenario is to combine metrics and logs on the same entity, namely, a host or a PGI.</p>\n<p>Example:</p>\n<pre><code class=\"hljs\">timeseries cpuIdle=avg(dt.host.cpu.idle), by: { host.name }, filter: { matches<span class=\"hljs-constructor\">Value(<span class=\"hljs-params\">host</span>.<span class=\"hljs-params\">name</span>, <span class=\"hljs-string\">&quot;ip-172-31-23-111.ec2.internal&quot;</span>)</span> }\n<span class=\"hljs-pattern-match\">| fields<span class=\"hljs-constructor\">Add</span> cpu<span class=\"hljs-constructor\">IdleAvg</span> = <span class=\"hljs-built_in\">array</span><span class=\"hljs-constructor\">Avg(<span class=\"hljs-params\">cpuIdle</span>)</span>\n| append\n[\n  timeseries cpu<span class=\"hljs-constructor\">Idle7dShift</span> = avg(dt.host.cpu.idle), by: { host.name }, filter: { matches<span class=\"hljs-constructor\">Value(<span class=\"hljs-params\">host</span>.<span class=\"hljs-params\">name</span>, <span class=\"hljs-string\">&quot;ip-172-31-23-111.ec2.internal&quot;</span>)</span> }, shift: -168h\n  | fields<span class=\"hljs-constructor\">Add</span> cpu<span class=\"hljs-constructor\">IdleAvg7dShift</span> = <span class=\"hljs-built_in\">array</span><span class=\"hljs-constructor\">Avg(<span class=\"hljs-params\">cpuIdle7dShift</span>)</span>\n]\n</span></code></pre>\n<p><img src=\"assets/host_idle_cpu_append.png\" alt=\"append for host idle CPU\" /></p>\n<p><strong>⏩ Try it out</strong>: Let's say you're investigating a JVM memory leak on host <code>i-0d8d16e6f7c82fd48</code>. To do so, we would like to get the heap details for that host combined with the server's logs. Using <code>append</code>, stitch together the heap metric (hint: <code>dt.runtime.jvm.memory_pool.used</code>) with the <code>WARN</code> and <code>ERROR</code> logs for that host. Make a timeseries for the log count (hint: <code>| makeTimeseries count=count()</code>), and plot both timeseries on the same time selection (e.g., <strong>Last 2 hours</strong>).  </p>","activityList":[]},{"id":"2.2","name":"Connecting Data With `join` and `lookup`","content":"<h2 id=\"connectingdatawithjoinandlookup\">Connecting Data With <code>join</code> and <code>lookup</code></h2>\n<h3 id=\"connectingdatawithlookup\">Connecting Data With <code>lookup</code></h3>\n<p>The <code>lookup</code> command (<a href=\"https://docs.dynatrace.com/docs/discover-dynatrace/references/dynatrace-query-language/commands/correlation-and-join-commands#lookup\">documentation</a>) adds (joins) fields from a subquery (the lookup table, set <code>B</code>, the \"right\") to the source table (set <code>A</code>, the \"left\") by finding a match between a field in the source table (<code>sourceField</code>) and the lookup table (<code>lookupField</code>). </p>\n<p>This mimics a SQL INNER JOIN, but it is not quite the same as an INNER JOIN, as <code>lookup</code> only returns the first matching result between <code>A</code> (\"left\") and <code>B</code> (\"right\"). Additional matches are disregarded.</p>\n<p><img src=\"assets/lookup_set_diagram.png\" alt=\"lookup Set Logic\" /></p>\n<p>Other points to note about <code>lookup</code>:</p>\n<ul>\n<li>Null Values: If the key values are null for <code>sourceField</code> and <code>lookupField</code>, then those records are not returned, as well. </li>\n<li>Nesting: <code>lookup</code> function nests all included fields as a record.</li>\n<li>Execution Order: By default, this is set to <code>auto</code>, which corresponds to the left (<code>A</code>) table being the source and the right (<code>B</code>) table being the lookup table. This can be changed to <code>leftFirst</code> or <code>rightFirst</code>, depending on what you are trying to do.</li>\n</ul>\n<p>Example query for <code>lookup</code> for service IDs from log records:</p>\n<pre><code class=\"hljs\"><span class=\"hljs-keyword\">fetch</span> logs\n| lookup \n[\n  <span class=\"hljs-keyword\">fetch</span> dt.entity.service\n  | fieldsAdd id\n  | fieldsAdd entity.name\n], sourceField: dt.source_entity, lookupField:id, prefix:&quot;service.&quot;\n| <span class=\"hljs-keyword\">filter</span> isNotNull(service.entity.name)\n</code></pre>\n<p>In the example, the log records have source entities that can be services (i.e., <code>dt.entity.service</code>). We want to match source entities that are services against the right (<code>B</code>) table in the Dynatrace entity model that has additional service details, like name, PGI the service runs on, and so on. </p>\n<p>To do that, we fetch records from <code>dt.entity.service</code> and match the source entity ID (<code>dt.source_entity</code>) with the entity ID from <code>dt.entity.service</code>. While <code>entity.name</code> and <code>id</code> are fields that are added by default with a <code>fetch</code> for entities in the entity model, it is good practice to add them as separate fields regardless, making the mapping of <code>sourceField</code> to <code>lookupField</code> more intuitive. Finally, the <code>prefix:</code> field allows you to place text in front of all keys in the result of the <code>lookup</code>. </p>\n<p><code>prefix:</code> will also manifest again when we discuss <code>join</code>.</p>\n<p>Please note that <code>lookup</code> only returns the <em>first</em> match for the left (<code>A</code>) and right (<code>B</code>) tables. That is apparent from this example DQL snippet and the screenshot below:</p>\n<pre><code class=\"hljs\">data record<span class=\"hljs-comment\">(a=2)</span>,\nrecord<span class=\"hljs-comment\">(a=4)</span>,\nrecord<span class=\"hljs-comment\">(a=6)</span>\n| lookup \n[\n  data record<span class=\"hljs-comment\">(a=2)</span>,\n  record<span class=\"hljs-comment\">(a=2)</span>,\n  record<span class=\"hljs-comment\">(a=3)</span>\n], sourceField: a, lookupField: a, prefix:<span class=\"hljs-string\">&quot;lookup.&quot;</span>\n</code></pre>\n<p><img src=\"assets/left_and_right_tables_lookup.png\" alt=\"A & B Tables, lookup\" /></p>\n<p><strong>⏩ Try it out</strong>: Following the DQL snippet below, <code>lookup</code> the names of the services running on a given process group. Note that you will need to add in the second <code>lookup</code>.  </p>\n<pre><code class=\"hljs\">fetch logs\n<span class=\"hljs-string\">| filter log.source == &quot;</span>/home/ubuntu/.dynaTrace/easyTravel <span class=\"hljs-number\">2.0</span>.<span class=\"hljs-number\">0</span>/easyTravel/<span class=\"hljs-built_in\">log</span>/BusinessBackend.<span class=\"hljs-built_in\">log</span><span class=\"hljs-string\">&quot;</span>\n<span class=\"hljs-string\">| lookup </span>\n[\n  fetch dt.entity.process_group_instance\n  <span class=\"hljs-string\">| fieldsAdd id</span>\n  <span class=\"hljs-string\">| fieldsAdd entity.name</span>\n  <span class=\"hljs-string\">| fieldsAdd services=runs[dt.entity.service]</span>\n  <span class=\"hljs-string\">| expand serviceId=services</span>\n], sourceField: dt.source_entity, lookupField:id, prefix:<span class=\"hljs-string\">&quot;pgi.&quot;</span>\n<span class=\"hljs-string\">| filter isNotNull(pgi.entity.name)</span>\n<span class=\"hljs-string\">| lookup </span>\n[\n\n]\n</code></pre>\n<p>Once successful, you will notice that <code>BookingService</code> is the only service name returned. More on why that's the case later….</p>\n<h3 id=\"exploringtheentitymodelandsemanticdictionarywithdescribe\">Exploring the Entity Model and Semantic Dictionary with <code>describe</code></h3>\n<p>A quite common scenario when using <code>lookup</code> or <code>join</code> is the need to map the relationships between one key in an observability facet (log, trace, metric) to either another facet or to the topology model itself. A powerful resource for that is the Dynatrace <a href=\"https://docs.dynatrace.com/docs/discover-dynatrace/references/semantic-dictionary\">semantic dictionary</a>, a reference that outlines the standards used for monitoring data in Dynatrace and their respective domain-specific data models. </p>\n<p>Using DQL, a quick way to determine what data model fields are present for a given data object / entity is by using <code>describe</code>. By running <code>describe</code>, Dynatrace will retrieve the on-read schema definition for that data object. </p>\n<p>Syntax:</p>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">describe entityObject</span>\n</code></pre>\n<p>For instance, if you run <code>describe dt.entity.process_group_instance</code>, you will then know all the possible fields and their data types for the PGI entity in the entity model. Many entity queries will only return the <code>id</code> and <code>entity.name</code> fields on a <code>fetch</code>, and therefore you will need to use <code>describe</code> and the semantic dictionary to ascertain what other fields to add to the <code>fetch</code>. </p>\n<p>As a way to \"automate\" the field addition for given <code>fetch</code>, let's use that <code>describe dt.entity.process_group_instance</code> call, export the result as a CSV, and then open the output in Excel. From Excel, we can transform the <code>field</code> column to add in all fields to a <code>fetch</code> using the Excel formula below:</p>\n<pre><code class=\"hljs\">=<span class=\"hljs-built_in\">CONCAT</span>(<span class=\"hljs-string\">&quot;| fieldsAdd &quot;</span>,<span class=\"hljs-symbol\">A2</span>) \n</code></pre>\n<p>(propagate <code>A2</code> to <code>A3</code>, <code>A4</code>, etc.)</p>\n<p>The result should look something like the screenshot below.\n<img src=\"assets/describe_excel.png\" alt=\"describe Output in Excel\" />\n<img src=\"assets/describe_output.png\" alt=\"describe Fields Added in DQL\" /></p>\n<p>For convenience, a summary of common topologies for the application, service, process, and host entities is given in the table below. The table will often get you a majority of the relationships that you would care about for these entities.</p>\n<table>\n<thead>\n<tr>\n<th>Entity model call</th>\n<th><code>belongs_to</code></th>\n<th><code>instance_of</code></th>\n<th><code>calls</code></th>\n<th><code>called_by</code></th>\n<th><code>runs</code></th>\n<th><code>runs_on</code></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>dt.entity.application</code></td>\n<td><em>N/A</em></td>\n<td><em>N/A</em></td>\n<td>Outbound calls to services (RUM to server-side correlation)</td>\n<td><em>N/A</em></td>\n<td><em>N/A</em></td>\n<td><em>N/A</em></td>\n</tr>\n<tr>\n<td><code>dt.entity.service</code></td>\n<td>Cloud application instance, namespace, container group, and/or queue that the service belongs to</td>\n<td><em>N/A</em></td>\n<td>Outbound calls to other services</td>\n<td>Inbound calls from other services</td>\n<td><em>N/A</em></td>\n<td>PGI, PG, and host service runs on</td>\n</tr>\n<tr>\n<td><code>dt.entity.process_group_instance</code></td>\n<td>Host that the PGI runs on</td>\n<td>Process group (PG) corresponding to PGI</td>\n<td>Outbound calls to other PGIs</td>\n<td>Inbound calls from other PGIs</td>\n<td>Services running on the PGI</td>\n<td><em>N/A</em></td>\n</tr>\n<tr>\n<td><code>dt.entity.process_group</code></td>\n<td>Cloud application instance, namespace, and container group that the PG runs on</td>\n<td><em>N/A</em></td>\n<td>Outbound calls to other PGs</td>\n<td>Inbound calls from other PGs</td>\n<td>Services running on the PG</td>\n<td>Hosts the PG runs on</td>\n</tr>\n<tr>\n<td><code>dt.entity.host</code></td>\n<td>Data center / AZ / region that the host runs on</td>\n<td>Host group corresponding to the host, if defined</td>\n<td>Outbound calls to other hosts</td>\n<td>Inbound calls from other hosts</td>\n<td>PGs running on the host</td>\n<td>Cloud or VM instance corresponding to host</td>\n</tr>\n</tbody>\n</table>\n<p><strong>⏩ Try it out</strong>: Determine how many load balancer data fields are present in the Dynatrace data model for an AWS application load balancer. </p>\n<p><strong>⏩ Try it out</strong>: Starting with the DQL snippet for a host system CPU timeseries (see below), use <code>describe</code> and <code>lookup</code> to figure out the AWS Availability Zone for that server. You will need two <code>lookup</code> commands.</p>\n<p>Snippet:</p>\n<pre><code class=\"hljs\">timeseries avg(dt.host.cpu.system), by: { host.name, dt.entity.host }, filter: { matches<span class=\"hljs-constructor\">Value(<span class=\"hljs-params\">host</span>.<span class=\"hljs-params\">name</span>, <span class=\"hljs-string\">&quot;ip-172-31-23-111.ec2.internal&quot;</span>)</span> }\n<span class=\"hljs-pattern-match\">| fields<span class=\"hljs-constructor\">Add</span> value.<span class=\"hljs-constructor\">A</span> = <span class=\"hljs-built_in\">array</span><span class=\"hljs-constructor\">Avg(`<span class=\"hljs-params\">avg</span>(<span class=\"hljs-params\">dt</span>.<span class=\"hljs-params\">host</span>.<span class=\"hljs-params\">cpu</span>.<span class=\"hljs-params\">system</span>)</span>`)\n| fields<span class=\"hljs-constructor\">Add</span> host<span class=\"hljs-constructor\">Id</span> = entity<span class=\"hljs-constructor\">Attr(<span class=\"hljs-params\">dt</span>.<span class=\"hljs-params\">entity</span>.<span class=\"hljs-params\">host</span>, <span class=\"hljs-string\">&quot;id&quot;</span>)</span>\n| lookup \n[\n\n]\n| lookup\n[\n\n]\n</span></code></pre>\n<p>Output:\n<img src=\"assets/lookup_aws_az.png\" alt=\"AWS Availability Zone\" /></p>\n<h3 id=\"topologytraversalandintentpassingwithentityattr\">Topology Traversal and Intent Passing With <code>entityAttr</code></h3>\n<p>In the last exercise, note the use of the command <code>entityAttr</code>: <a href=\"https://docs.dynatrace.com/docs/discover-dynatrace/references/dynatrace-query-language/functions/general-functions#entity-attr\">Documentation</a>. This command allows you to traverse the Dynatrace data model for a given entity (for example, <code>dt.entity.host</code>) on a particular field for that model. However, to do that, you need to know the fields that you have for that data object, likely requiring you to use <code>describe</code> to get those details.</p>\n<p>Let's say you wanted to grab all outbound PGI callers for a particular PGI using <code>entityAttr</code>. You're getting that process information from its CPU usage. To do that, you could first describe <code>dt.entity.process_group_instance</code> and find the fields for that data object. Then, you would find the fields you care about and call them out for that data object with the following approach:</p>\n<pre><code class=\"hljs\">timeseries avg(dt.process.cpu.usage), by: { dt.entity.process_group_instance }\n<span class=\"hljs-pattern-match\">| fields<span class=\"hljs-constructor\">Add</span> entity.name = entity<span class=\"hljs-constructor\">Name(<span class=\"hljs-params\">dt</span>.<span class=\"hljs-params\">entity</span>.<span class=\"hljs-params\">process_group_instance</span>)</span>\n| fields<span class=\"hljs-constructor\">Add</span> id = entity<span class=\"hljs-constructor\">Attr(<span class=\"hljs-params\">dt</span>.<span class=\"hljs-params\">entity</span>.<span class=\"hljs-params\">process_group_instance</span>, <span class=\"hljs-string\">&quot;id&quot;</span>)</span>\n| fields<span class=\"hljs-constructor\">Add</span> calls = entity<span class=\"hljs-constructor\">Attr(<span class=\"hljs-params\">dt</span>.<span class=\"hljs-params\">entity</span>.<span class=\"hljs-params\">process_group_instance</span>, <span class=\"hljs-string\">&quot;calls&quot;</span>)</span>\n| fields<span class=\"hljs-constructor\">Add</span> outbound<span class=\"hljs-constructor\">PGICount</span> = <span class=\"hljs-built_in\">array</span><span class=\"hljs-constructor\">Size(<span class=\"hljs-params\">calls</span>[<span class=\"hljs-params\">dt</span>.<span class=\"hljs-params\">entity</span>.<span class=\"hljs-params\">process_group_instance</span>])</span>\n| expand outbound<span class=\"hljs-constructor\">PGI</span> = calls[dt.entity.process<span class=\"hljs-constructor\">_group_instance</span>]\n</span></code></pre>\n<p>Here, the <code>dt.entity.process_group_instance</code> data object has additional semantic details added via <code>entityAttr</code> with the <code>id</code> and <code>calls</code> lines. For any data object, you can use <code>entityName</code> to return the <code>entity.name</code> field for that object. <code>calls</code> is what is used for outbound PGI callers, and that line then returns an array of PGIs that are called by a particular process. As such, you can get a count of the outbound PGIs from that process by using <code>arraySize</code>, and then you can map the individual PGIs themselves through an <code>expand</code>. </p>\n<p>To map the array elements appropriately, you need to call the suitable object for that topological link; for <code>calls</code> and <code>called_by</code> with <code>dt.entity.process_group_instance</code>, you will use <code>dt.entity.process_group_instance</code>, but this could vary based on what you are linking topologically. For example, if you were referencing <code>runs</code> with <code>dt.entity.process_group_instance</code>, you would want to return a list of services, and therefore you would use <code>dt.entity.service</code> instead.</p>\n<p>When you use <code>entityAttr</code>, your queries are enriched with the entity model, thereby allowing you to pass intents between apps. In turn, you can perform an <strong>Open record with</strong> to other apps on records returned by a query. Without <code>entityAttr</code>, you often will unable to pass intents appropriately, preventing you from opening the record elsewhere.</p>\n<p><strong>⏩ Try it out</strong>: Take the previous snippet and modify it to get the process group (PG) name using <code>entityAttr</code>. Open the PG in another app with <strong>Open record with</strong>. Which entity is passed through the intent?</p>\n<h3 id=\"flexibledataconnectivitywithjoin\">Flexible Data Connectivity With <code>join</code></h3>\n<p>The <code>join</code> command (<a href=\"https://docs.dynatrace.com/docs/discover-dynatrace/references/dynatrace-query-language/commands/correlation-and-join-commands#join\">documentation</a>) adds (joins) fields from a subquery (set <code>B</code>, the \"right\") to the source table (set <code>A</code>, the \"left\"). The <code>join</code> can be done with three different <code>kind</code> values:</p>\n<table>\n<thead>\n<tr>\n<th><code>join</code> type</th>\n<th><code>kind</code> value</th>\n<th>Description</th>\n<th>SQL Equivalent</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Inner Join</td>\n<td><code>kind: inner</code></td>\n<td>Returns only the matching records from both tables (<code>A</code> and <code>B</code>).</td>\n<td>SQL INNER JOIN</td>\n</tr>\n<tr>\n<td>Left Outer Join</td>\n<td><code>kind: leftOuter</code></td>\n<td>Returns all records from the left table (<code>A</code>) and the matching records from the right table (<code>B</code>). If no match is found, the result will be <code>null</code> for the right table's fields.</td>\n<td>SQL LEFT OUTER JOIN</td>\n</tr>\n<tr>\n<td>Outer Join</td>\n<td><code>kind: outer</code></td>\n<td>Returns all matching and non-matching records from the left table (<code>A</code>) and the right table (<code>B</code>).</td>\n<td>SQL OUTER JOIN</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Inner Join</strong>\n<img src=\"assets/inner_join_set_diagram.png\" alt=\"Inner Join\" /></p>\n<p><strong>Left Outer Join</strong>\n<img src=\"assets/left_outer_join_set_diagram.png\" alt=\"Left Outer Join\" /></p>\n<p><strong>Outer Join</strong>\n<img src=\"assets/outer_join_set_diagram.png\" alt=\"Outer Join\" /></p>\n<p>Let's walk through an example query for an inner <code>join</code> for service IDs from log records:</p>\n<pre><code class=\"hljs\"><span class=\"hljs-keyword\">fetch</span> logs\n| <span class=\"hljs-keyword\">join</span>\n[\n  <span class=\"hljs-keyword\">fetch</span> dt.entity.service\n  | fieldsAdd id\n  | fieldsAdd entity.name\n], kind:{<span class=\"hljs-keyword\">inner</span>}, <span class=\"hljs-keyword\">on</span>:{left[dt.source_entity] == right[id]}, prefix: &quot;service.&quot;\n| <span class=\"hljs-keyword\">filter</span> isNotNull(service.entity.name)\n</code></pre>\n<p>Similar to a <code>lookup</code>, we are mapping the field <code>dt.source_entity</code> in the left (<code>A</code>) table to service IDs in the right (<code>B</code>) table. The mapping is accomplished by the line: <code>on:{left[dt.source_entity] == right[id]}</code>. To use an inner join, we set <code>kind:{inner}</code>. Finally, we add a prefix \"service.\" to all resulting entries. Like <code>lookup</code>, it is good practice to place the right-side mapping field (here, <code>id</code>) in the query, as well as <code>entity.name</code>. </p>\n<p>If there are no matches between the left (<code>A</code>) table and the right (<code>B</code>) table, then, for a <code>join</code> using <code>kind:{inner}</code>, you will have no records returned. Unlike <code>lookup</code>, <code>join</code> will match past the first record. </p>\n<p>Using a left outer join (i.e., <code>kind:{leftOuter}</code>) is useful for finding both matching and non-matching records, as those that do not match on the right (<code>B</code>) table will return as null. In this scenario, you are guaranteed to return some records, with <em>null</em> values for non-matches. </p>\n<p>Let's look at this for a similar version of the previous DQL logs snippet. In this case, we have adjusted the service ID with <code>concat</code> to deliberately break the matches for the right table on a <code>leftOuter</code> join.</p>\n<pre><code class=\"hljs\">fetch logs\n| <span class=\"hljs-type\">join</span>\n[\n  fetch dt.entity.service\n  | <span class=\"hljs-type\">fieldsAdd</span> id\n  | <span class=\"hljs-type\">fieldsAdd</span> newId = concat(id,<span class=\"hljs-string\">&quot;1&quot;</span>)\n  | <span class=\"hljs-type\">fieldsAdd</span> entity.name\n], kind:{leftOuter}, on:{<span class=\"hljs-built_in\">left</span>[dt.source_entity] == <span class=\"hljs-built_in\">right</span>[newId]}, prefix: <span class=\"hljs-string\">&quot;service.&quot;</span>\n| <span class=\"hljs-type\">limit</span> <span class=\"hljs-number\">10</span>\n</code></pre>\n<p>Run this with both <code>leftOuter</code> and <code>inner</code> joins. You will notice that <code>leftOuter</code> returns records with null fields while <code>inner</code> does not. </p>\n<p><img src=\"assets/leftouter_and_inner_same_query.png\" alt=\"leftouter and inner\" /></p>\n<p><strong>⏩ Try it out</strong>: Starting with the snippet below, modify it so that you can determine the single value percentage of EC2 instances in the environment. Hint: on your <code>summarize</code>, you will need to use a <code>countIf</code>. What happens when you change the <code>kind:</code> value for <code>join</code>?</p>\n<pre><code class=\"hljs\">timeseries avg(dt.host.cpu.usage), by: { dt.entity.host }\n<span class=\"hljs-pattern-match\">| fields<span class=\"hljs-constructor\">Add</span> dt.entity.host.name = entity<span class=\"hljs-constructor\">Name(<span class=\"hljs-params\">dt</span>.<span class=\"hljs-params\">entity</span>.<span class=\"hljs-params\">host</span>)</span>\n| fields<span class=\"hljs-constructor\">Add</span> value.<span class=\"hljs-constructor\">A</span> = <span class=\"hljs-built_in\">array</span><span class=\"hljs-constructor\">Avg(`<span class=\"hljs-params\">avg</span>(<span class=\"hljs-params\">dt</span>.<span class=\"hljs-params\">host</span>.<span class=\"hljs-params\">cpu</span>.<span class=\"hljs-params\">usage</span>)</span>`)\n\n<span class=\"hljs-operator\">...</span>\n| fields ec2<span class=\"hljs-constructor\">Percentage</span>\n</span></code></pre>","activityList":[]},{"id":"2.3","name":"Wrap Up","content":"<h2 id=\"wrapup\">Wrap Up</h2>\n<h3 id=\"whatyoulearnedtoday\">What You Learned Today</h3>\n<p>You explored how to connect data using the <code>append</code>, <code>data</code>, <code>lookup</code>, and <code>join</code> commands in DQL to combine data from multiple sources. </p>\n<p>Understanding <code>data</code>:</p>\n<ul>\n<li>The <code>data</code> command allows you to add any data into a Notebook, Dashboard, Workflow, or other DQL components.</li>\n<li>It's useful for pulling in data from other sources like Excel or CSV files.</li>\n<li>JSON data types are allowed.</li>\n</ul>\n<p>You explored an example of nested JSON and learned how to parse it using <code>fieldsFlatten</code> and <code>fieldsKeep</code>.</p>\n<p>Adding Data Sets with <code>append</code>:</p>\n<ul>\n<li>The append command behaves similarly to a SQL UNION ALL operation, combining two data sets.</li>\n<li>You learned how to use append to combine metrics and logs on the same entity.</li>\n</ul>\n<p>Understanding <code>lookup</code>:</p>\n<ul>\n<li>The <code>lookup</code> command adds fields from a subquery (lookup table) to the source table by matching fields.</li>\n<li>It mimics a SQL INNER JOIN but only returns the first matching result.</li>\n<li>Null values in key fields are not returned.</li>\n<li>The lookup function nests all included fields as a record.</li>\n</ul>\n<p>In addition, you explored the entity model with <code>describe</code>. The <code>describe</code> command helps you understand the data model fields present for a given entity. You can use the Dynatrace semantic dictionary to map relationships between keys in different observability facets.</p>\n<p>A summary of the common topologies for application, service, process, and host entities was provided to help you understand relationships in the Dynatrace data model.</p>\n<p>You also delved into the <code>entityAttr</code> command in DQL, which allows you to traverse the Dynatrace data model for a given entity on a particular field. Often, you may need to use <code>describe</code> to understand the fields available for the data object to be suitably used in <code>entityAttr</code>. This command enriches your queries and allows you to pass intents between apps.  </p>\n<p>Finally, you explored the <code>join</code> command in DQL. </p>\n<p>Understanding <code>join</code>:</p>\n<ul>\n<li>The join command adds fields from a subquery (set <code>B</code>, the \"right\") to the source table (set <code>A</code>, the \"left\").</li>\n<li>There are three types of joins: <code>inner</code>, <code>leftOuter</code>, and <code>outer</code>.</li>\n</ul>\n<p>Types of Joins:</p>\n<ul>\n<li>Inner Join (kind: inner): Returns only the matching records from both tables.</li>\n<li>Left Outer Join (kind: leftOuter): Returns all records from the left table and the matching records from the right table. Non-matching records from the right table are returned as null.</li>\n<li>Outer Join (kind: outer): Returns all matching and non-matching records from both tables.</li>\n</ul>\n<p>By mastering these concepts, you can effectively connect and analyze data in Dynatrace, enhancing your observability and monitoring capabilities. Keep practicing with the provided exercises to solidify your understanding! 🚀</p>","activityList":[]}]},{"id":"3","name":"Query Optimization","content":"<h2 id=\"queryoptimization\">Query Optimization</h2>\n<h3 id=\"importnotebookintodynatrace\">Import Notebook into Dynatrace</h3>\n<p><a href=\"https://github.com/popecruzdt/dt-k8s-otel-o11y-logs/blob/code-spaces/dt-k8s-otel-o11y-logs_dt_notebook.json\">Notebook</a></p>\n<h3 id=\"whyaremyqueriesarepoorlyperforming\">Why are my queries are poorly performing?</h3>\n<p>Whenever your query is executed against a large data volume in a single bucket, it will likely not perform well. In turn, you should have a systematic bucket strategy and utilize segments, as these are the highest priority filters when executing a DQL query. Put simply, filter early and often.</p>\n<p>However, there are some query patterns that return large data amounts by definition, and therefore you should execute these queries with caution, as they potentially will not be performative:</p>\n<ul>\n<li>Log records past the default limit of 1000 records</li>\n<li>Queries with multiple <code>lookup</code> or <code>join</code> statements</li>\n<li>Trace and span data</li>\n</ul>\n<p>As an example, take the following query:</p>\n<pre><code class=\"hljs\">fetch spans, <span class=\"hljs-keyword\">from</span>:now()<span class=\"hljs-number\">-14</span>d, <span class=\"hljs-keyword\">to</span>:now()\n| makeTimeseries <span class=\"hljs-built_in\">count</span>=<span class=\"hljs-built_in\">count</span>()\n</code></pre>\n<p>That query looks to produce a request count timeseries over the last 2 weeks. By running it in a Notebook, you can note the execution time (shown below).</p>\n<p><img src=\"assets/spans_14days.png\" alt=\"DQL Execution Time\" /></p>\n<p>Typically, this query will run in ~5 s. If we apply some K8s namepsace segments - in this case, say <code>easyTrade</code>, <code>prod</code>, <code>pvc-demo</code>, and <code>travel-advisor-demo</code> - the query's performance improves to ~1 s. Since segments are applied as a priority filter, the performance gets better. This is crucial when placing queries on multiple tiles with variable filters in Dashboards; while some parallelization can occur on a Dashboard, this can become limited if the query is drawing from the same data source and/or bucket. </p>\n<p><img src=\"assets/spans_with_segments.png\" alt=\"Spans with Segments\" /></p>\n<p>In addition to the execution time, please note the number of scanned records and bytes before and after the application of the segment. Here, the number of scanned records remains constant, while the number of scanned bytes and execution time increases when the segment is removed. </p>\n<p><strong>⏩ Try it out</strong>: Looking at the query performance before and after segment application, can you explain why the record count is unchanged? Is the retrieval time per record constant?</p>\n<p>You may also notice that if you run a query for the first time and then run it again, the performance improves. Behind the scenes, there is query caching taking place. Depending on environment, you can see up to a <em>70% improvement in query execution time</em> for cached queries, but that number is heuristic, dependent on bucket utilization, query structure, data type, etc.</p>\n<p><strong>⏩ Try it out</strong>: Let's say we want to determine the log count coming from services in the last 24 hours. We know that we have logs spanning multiple AWS Availability Zones (AZs) in the <code>us-east</code> region. In turn, we want to be able to analyze logs coming from those AZs. Make a segment titled <code>AWS Availability Zones</code> that allows you to select a particular AZ for the log records. You likely will need to use <code>join</code> or <code>lookup</code> to do this (hint: see last example in the <strong>Data Transformation</strong> section). When you have that, run the query below, and note the performance before and after segment application.</p>\n<p>Snippet:</p>\n<pre><code class=\"hljs\">fetch logs, <span class=\"hljs-keyword\">from</span>:now()<span class=\"hljs-number\">-1</span>d, <span class=\"hljs-keyword\">to</span>:now()\n| lookup \n[\n  fetch dt.entity.process_group_instance\n  | fieldsAdd <span class=\"hljs-built_in\">id</span>\n  | fieldsAdd entity.<span class=\"hljs-built_in\">name</span>\n  | fieldsAdd services=runs[dt.entity.service]\n  | expand serviceId=services\n], sourceField: dt.source_entity, lookupField:<span class=\"hljs-built_in\">id</span>, prefix:<span class=\"hljs-string\">&quot;pgi.&quot;</span>\n| filter isNotNull(pgi.entity.<span class=\"hljs-built_in\">name</span>)\n| lookup \n[\n  fetch dt.entity.service\n  | fieldsAdd <span class=\"hljs-built_in\">id</span>\n  | fieldsAdd entity.<span class=\"hljs-built_in\">name</span>\n], sourceField: pgi.serviceId, lookupField:<span class=\"hljs-built_in\">id</span>, prefix:<span class=\"hljs-string\">&quot;service.&quot;</span>\n| <span class=\"hljs-built_in\">summarize</span> <span class=\"hljs-built_in\">count</span>=<span class=\"hljs-built_in\">count</span>(), <span class=\"hljs-keyword\">by</span>:{service.entity.<span class=\"hljs-built_in\">name</span>}\n</code></pre>\n<p><img src=\"assets/aws_az_segment.png\" alt=\"AZ Segment\" /></p>\n<h3 id=\"improvingquerieswithsamplingratio\">Improving Queries with <code>samplingRatio</code></h3>\n<p>For DQL queries, we can use <code>samplingRatio</code> to randomly sample records from an initial <code>fetch</code> call. Depending on the specified value, a fraction (1/<code>samplingRatio</code>) of the available raw records is returned.</p>\n<p>While any value less than or equal to 10000 can be used, the typical applicable value ranges for sampling are:</p>\n<ul>\n<li>1: Default value, resulting in no applied sampling.</li>\n<li>10</li>\n<li>100</li>\n<li>1000</li>\n<li>10000</li>\n</ul>\n<p>An example query with <code>samplingRatio</code> is given as follows:</p>\n<pre><code class=\"hljs\">fetch logs, <span class=\"hljs-keyword\">from</span>:now()<span class=\"hljs-number\">-7</span>d, <span class=\"hljs-keyword\">to</span>:now() samplingRatio:<span class=\"hljs-number\">100</span>\n| <span class=\"hljs-built_in\">summarize</span> <span class=\"hljs-built_in\">count</span> = countIf(loglevel == <span class=\"hljs-string\">&quot;ERROR&quot;</span>), <span class=\"hljs-keyword\">by</span>:bin(timestamp, <span class=\"hljs-number\">3</span>h)\n| fieldsAdd <span class=\"hljs-built_in\">count</span> = <span class=\"hljs-built_in\">count</span>*<span class=\"hljs-number\">100</span>\n</code></pre>\n<p>Note that if you sample a query with counts, you should extrapolate the count to the order of magnitude used for <code>samplingRatio</code>. This is based on the fact that the the number of records returned after applying <code>samplingRatio</code> is non-linear, as seen in the figure below (sharding on the Grail data lakehouse backend). </p>\n<p><img src=\"assets/sampling_ratio_step_function.png\" alt=\"Sampling Ratio Step Function\" /></p>\n<p>Certain queries - like request count and other simple DQL queries that do not need to split on a high-cardinality dimension - can perform well with sampling ratio. You can extrapolate the results so that the discarded counts or response time mimic the actual results. Sampling ratio does not affect the nominal retrieval time per record; that is dictated by the buckets used in the backend. </p>\n<p>If specific, potentially high cardinality dimensions are needed, then the sampling ratio likely cannot be used to improve performance. Specific records will likely be omitted at higher sampling ratio values. </p>\n<p><strong>⏩ Try it out</strong>: Let's say we want to determine the log count coming from services in the last 24 hours. We know that we have logs spanning multiple AWS Availability Zones (AZs) in the <code>us-east</code> region. In turn, we want to be able to analyze logs coming from those AZs. Make a segment titled <code>AWS Availability Zones</code> that allows you to select a particular AZ for the log records. You likely will need to use <code>join</code> or <code>lookup</code> to do this (hint: see last example in the <strong>Data Transformation</strong> section). When you have that, run the query below, and note the performance before and after segment application.</p>\n<h3 id=\"enrichinghighvolumedataasmetrics\">Enriching High Volume Data as Metrics</h3>","activityList":[]},{"id":"4","name":"Complex Query Aggregation by Workflows","content":"<h2 id=\"complexqueryaggregationbyworkflows\">Complex Query Aggregation by Workflows</h2>\n<h3 id=\"whatyoulllearntoday\">What You’ll Learn Today</h3>\n<p>In the <em>tacocorp</em> environment, we are going to walk through a workflow that takes a number of queries and aggregates the results as business events.</p>\n<p><a href=\"https://bwm98081.apps.dynatrace.com/\">tacocorp</a></p>","activityList":[]},{"id":"5","name":"Wrap Up","content":"<h2 id=\"wrapup\">Wrap Up</h2>\n<h3 id=\"kuberneteskindcluster\">Kubernetes Kind Cluster</h3>\n<p><a href=\"https://github.com/popecruzdt/dt-k8s-otel-o11y-cluster/tree/code-spaces\">dt-k8s-otel-o11y-cluster</a></p>\n<h3 id=\"opentelemetrycollectorforlogs\">OpenTelemetry Collector for Logs</h3>\n<p><a href=\"https://github.com/popecruzdt/dt-k8s-otel-o11y-logs/tree/code-spaces\">dt-k8s-otel-o11y-logs</a></p>\n<h3 id=\"opentelemetrycollectorfortraces\">OpenTelemetry Collector for Traces</h3>\n<p><a href=\"https://github.com/popecruzdt/dt-k8s-otel-o11y-traces/tree/code-spaces\">dt-k8s-otel-o11y-traces</a></p>\n<h3 id=\"opentelemetrycollectorformetrics\">OpenTelemetry Collector for Metrics</h3>\n<p><a href=\"https://github.com/popecruzdt/dt-k8s-otel-o11y-metrics/tree/code-spaces\">dt-k8s-otel-o11y-metrics</a></p>\n<h3 id=\"opentelemetrycollectorcapstone\">OpenTelemetry Collector Capstone</h3>\n<p><a href=\"https://github.com/popecruzdt/dt-k8s-otel-o11y-cap/tree/code-spaces\">dt-k8s-otel-o11y-cap</a></p>\n<h3 id=\"dtulabguide\">DTU Lab Guide</h3>\n<p><a href=\"https://github.com/popecruzdt/dt-k8s-otel-o11y-dtu\">dt-k8s-otel-o11y-dtu</a></p>","activityList":[]}]